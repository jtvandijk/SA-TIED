[
  {
    "objectID": "02-mapping-data.html",
    "href": "02-mapping-data.html",
    "title": "1 R for Spatial Analysis",
    "section": "",
    "text": "Open a new script within your Geospatial-Workshop24 project and save this as 02-language-maps.r. We will start again by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tmap)\n\n\n\n\n\nYou have been introduced to the tidyverse library last session, but now we are adding the sf library to read and load our spatial data as well as the tmap library to visualise our spatial data.\nWe will continue working with the .csv dataset that we prepared in the previous session, so we start by loading this:\n\n\n\nR code\n\n# load data\natt &lt;- read_csv(\"data/attributes/language.csv\")\n\n\nRows: 878 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): sp_code, sp_pop, sp_xhosa\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nYou can inspect the dataframe by using the View() function.\nNext, we need a corresponding spatial dataset that contains the Cape Town’s sub places and save it in your data/spatial folder.\n\n\n\nFile\nType\nLink\n\n\n\n\nCape Town Sub Places\nGeoPackage\nDownload\n\n\n\n\n\n\n\n\n\nYou may have used spatial data before and noticed that we did not download a collection of files known as a shapefile but a GeoPackage instead. Whilst shapefiles are still being used, GeoPackage is modern and portable file format. Have a look at this article on towardsdatascience.com for an excellent explanation on why one should use GeoPackage files over shapefiles where possible: [Link]\n\n\n\nLet us load the file and store it into an object called cpt. We can do this as follows:\n\n\n\nR code\n\n# load data\ncpt &lt;- st_read(\"data/spatial/subplace-cape-town-2013.gpkg\")\n\n\nReading layer `subplace-cape-town-2013' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/SA-TIED/data/spatial/subplace-cape-town-2013.gpkg' \n  using driver `GPKG'\nSimple feature collection with 921 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -64020.67 ymin: -3803551 xmax: 430.9835 ymax: -3705149\nProjected CRS: WGS_1984_Transverse_Mercator\n\n\nYou should also see the cpt variable appear in your environment window.\n\n\n\nAs this is the first time we have loaded spatial data into R, let’s go for a little exploration of how we can interact with our spatial dataframe. The first thing we want to do when we load spatial data is to make a quick map to check whether everything is in order. To do this, we can use the same function we used before: plot():\n\n\n\nR code\n\n# plot data\nplot(cpt, max.plot = 1)\n\n\n\n\n\nYou should see your cpt plot appear in your Plots window.\n\n\n\n\n\n\nThe plot() function should not to be used to make publishable maps but can be used as a quick way of inspecting your spatial data.\n\n\n\nJust as with a tabular dataframe, we can inspect the spatial data frame:\n\n\n\nR code\n\n# inspect columns, rows\nncol(cpt)\n\n\n[1] 17\n\nnrow(cpt)\n\n[1] 921\n\n# inspect data\nhead(cpt)\n\n# A tibble: 6 × 17\n  sp_code   sp_name    mp_code mp_name mn_mdb_c mn_code mn_name dc_mdb_c dc_mn_c\n  &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt;\n1 199035011 Greenfield  199035 Blue D… CPT          199 City o… CPT          199\n2 199035012 Wesbank     199035 Blue D… CPT          199 City o… CPT          199\n3 199035013 Kleinvlei   199035 Blue D… CPT          199 City o… CPT          199\n4 199035014 Palm Park   199035 Blue D… CPT          199 City o… CPT          199\n5 199035015 Park Vill…  199035 Blue D… CPT          199 City o… CPT          199\n6 199035016 Hill View   199035 Blue D… CPT          199 City o… CPT          199\n# ℹ 8 more variables: dc_name &lt;chr&gt;, pr_mdb_c &lt;chr&gt;, pr_code &lt;dbl&gt;,\n#   pr_name &lt;chr&gt;, albers_are &lt;dbl&gt;, shape_leng &lt;dbl&gt;, shape_area &lt;dbl&gt;,\n#   geom &lt;MULTIPOLYGON [m]&gt;\n\n# inspect column names\nnames(cpt)\n\n [1] \"sp_code\"    \"sp_name\"    \"mp_code\"    \"mp_name\"    \"mn_mdb_c\"  \n [6] \"mn_code\"    \"mn_name\"    \"dc_mdb_c\"   \"dc_mn_c\"    \"dc_name\"   \n[11] \"pr_mdb_c\"   \"pr_code\"    \"pr_name\"    \"albers_are\" \"shape_leng\"\n[16] \"shape_area\" \"geom\"      \n\n\nWe can also again establish the class of our data:\n\n\n\nR code\n\n# inspect\nclass(cpt)\n\n\n[1] \"sf\"         \"data.frame\"\n\n\nWe should see our data is an sf dataframe, which is what we want and we can move on.\n\n\n\nWe now have our language dataset (att) with the number of isiXhosa speakers in Cape Town, organised by sub-place, as well as a spatial dataset containing the boundaries of these sub-places (cpt). We can now join this table data to our spatial data using an Attribute Join.\n\n\n\n\n\n\nAn attribute join links two datasets based on a common attribute, enabling the ‘matching’ of rows between them.\n\n\n\n\n\nFigure 1: Attribute Joins.\n\n\n\n\nTo perform a successful join, each dataset must contain a unique identifying (UID) field. This could be a code, a name, or any other consistent identifier. It is crucial that the ID field is accurate across both datasets, with no typos or inconsistencies (e.g., “City of Cape Town” is not the same as “The City of Cape Town”). Whenever possible, it is preferable to use unique codes rather than names, as codes reduce the likelihood of errors and mismatches.\n\n\n\nBefore proceeding with the join, we need to verify that a matching UID exists in both datasets. Let’s look at the column names in our datasets again:\n\n\n\nR code\n\n# inspect\nnames(att)\n\n\n[1] \"sp_code\"  \"sp_pop\"   \"sp_xhosa\"\n\nnames(cpt)\n\n [1] \"sp_code\"    \"sp_name\"    \"mp_code\"    \"mp_name\"    \"mn_mdb_c\"  \n [6] \"mn_code\"    \"mn_name\"    \"dc_mdb_c\"   \"dc_mn_c\"    \"dc_name\"   \n[11] \"pr_mdb_c\"   \"pr_code\"    \"pr_name\"    \"albers_are\" \"shape_leng\"\n[16] \"shape_area\" \"geom\"      \n\n\nThe sp_code columns looks promising as it features in both datasets. We can quickly sort both columns and have a peek at the data:\n\n\n\nR code\n\n# inspect att\nhead(sort(att$sp_code))\n\n\n[1] 199001001 199002001 199002002 199002003 199003001 199004001\n\n# inspect cpt\nhead(sort(cpt$sp_code))\n\n[1] \"199001001\" \"199002001\" \"199002002\" \"199002003\" \"199003001\" \"199004001\"\n\n\nThey seem to contain similar values, so that is promising. Let us try to join the attribute data onto the spatial data:\n\n\n\nR code\n\n# join attribute data onto spatial data\ncpt &lt;- cpt |&gt;\n    left_join(att, by = c(sp_code = \"sp_code\"))\n\n\nYou will notice that the join results in an error.\nWhere the sub place codes in the att object are stored as numbers, the sub place codes in the cpt object are stored as strings. We can fix this by casting the number to characters:\n\n\n\nR code\n\n# change data type\natt &lt;- att |&gt;\n    mutate(sp_code = as.character(sp_code))\n\n# inspect\ntypeof(att$sp_code)\n\n\nWe can now try to join the datasets together again:\n\n\n\nR code\n\n# join attribute data onto spatial data\ncpt &lt;- cpt |&gt;\n    left_join(att, by = c(sp_code = \"sp_code\"))"
  },
  {
    "objectID": "02-mapping-data.html#loading-spatial-data",
    "href": "02-mapping-data.html#loading-spatial-data",
    "title": "1 R for Spatial Analysis",
    "section": "",
    "text": "Open a new script within your Geospatial-Workshop24 project and save this as 02-language-maps.r. We will start again by loading the libraries that we will need:\n\n\n\nR code\n\n# load libraries\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(tmap)\n\n\n\n\n\nYou have been introduced to the tidyverse library last session, but now we are adding the sf library to read and load our spatial data as well as the tmap library to visualise our spatial data.\nWe will continue working with the .csv dataset that we prepared in the previous session, so we start by loading this:\n\n\n\nR code\n\n# load data\natt &lt;- read_csv(\"data/attributes/language.csv\")\n\n\nRows: 878 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (3): sp_code, sp_pop, sp_xhosa\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nYou can inspect the dataframe by using the View() function.\nNext, we need a corresponding spatial dataset that contains the Cape Town’s sub places and save it in your data/spatial folder.\n\n\n\nFile\nType\nLink\n\n\n\n\nCape Town Sub Places\nGeoPackage\nDownload\n\n\n\n\n\n\n\n\n\nYou may have used spatial data before and noticed that we did not download a collection of files known as a shapefile but a GeoPackage instead. Whilst shapefiles are still being used, GeoPackage is modern and portable file format. Have a look at this article on towardsdatascience.com for an excellent explanation on why one should use GeoPackage files over shapefiles where possible: [Link]\n\n\n\nLet us load the file and store it into an object called cpt. We can do this as follows:\n\n\n\nR code\n\n# load data\ncpt &lt;- st_read(\"data/spatial/subplace-cape-town-2013.gpkg\")\n\n\nReading layer `subplace-cape-town-2013' from data source \n  `/Users/justinvandijk/Library/CloudStorage/Dropbox/UCL/Web/jtvandijk.github.io/SA-TIED/data/spatial/subplace-cape-town-2013.gpkg' \n  using driver `GPKG'\nSimple feature collection with 921 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -64020.67 ymin: -3803551 xmax: 430.9835 ymax: -3705149\nProjected CRS: WGS_1984_Transverse_Mercator\n\n\nYou should also see the cpt variable appear in your environment window."
  },
  {
    "objectID": "02-mapping-data.html#exploring-spatial-data",
    "href": "02-mapping-data.html#exploring-spatial-data",
    "title": "1 R for Spatial Analysis",
    "section": "",
    "text": "As this is the first time we have loaded spatial data into R, let’s go for a little exploration of how we can interact with our spatial dataframe. The first thing we want to do when we load spatial data is to make a quick map to check whether everything is in order. To do this, we can use the same function we used before: plot():\n\n\n\nR code\n\n# plot data\nplot(cpt, max.plot = 1)\n\n\n\n\n\nYou should see your cpt plot appear in your Plots window.\n\n\n\n\n\n\nThe plot() function should not to be used to make publishable maps but can be used as a quick way of inspecting your spatial data.\n\n\n\nJust as with a tabular dataframe, we can inspect the spatial data frame:\n\n\n\nR code\n\n# inspect columns, rows\nncol(cpt)\n\n\n[1] 17\n\nnrow(cpt)\n\n[1] 921\n\n# inspect data\nhead(cpt)\n\n# A tibble: 6 × 17\n  sp_code   sp_name    mp_code mp_name mn_mdb_c mn_code mn_name dc_mdb_c dc_mn_c\n  &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;      &lt;dbl&gt;\n1 199035011 Greenfield  199035 Blue D… CPT          199 City o… CPT          199\n2 199035012 Wesbank     199035 Blue D… CPT          199 City o… CPT          199\n3 199035013 Kleinvlei   199035 Blue D… CPT          199 City o… CPT          199\n4 199035014 Palm Park   199035 Blue D… CPT          199 City o… CPT          199\n5 199035015 Park Vill…  199035 Blue D… CPT          199 City o… CPT          199\n6 199035016 Hill View   199035 Blue D… CPT          199 City o… CPT          199\n# ℹ 8 more variables: dc_name &lt;chr&gt;, pr_mdb_c &lt;chr&gt;, pr_code &lt;dbl&gt;,\n#   pr_name &lt;chr&gt;, albers_are &lt;dbl&gt;, shape_leng &lt;dbl&gt;, shape_area &lt;dbl&gt;,\n#   geom &lt;MULTIPOLYGON [m]&gt;\n\n# inspect column names\nnames(cpt)\n\n [1] \"sp_code\"    \"sp_name\"    \"mp_code\"    \"mp_name\"    \"mn_mdb_c\"  \n [6] \"mn_code\"    \"mn_name\"    \"dc_mdb_c\"   \"dc_mn_c\"    \"dc_name\"   \n[11] \"pr_mdb_c\"   \"pr_code\"    \"pr_name\"    \"albers_are\" \"shape_leng\"\n[16] \"shape_area\" \"geom\"      \n\n\nWe can also again establish the class of our data:\n\n\n\nR code\n\n# inspect\nclass(cpt)\n\n\n[1] \"sf\"         \"data.frame\"\n\n\nWe should see our data is an sf dataframe, which is what we want and we can move on."
  },
  {
    "objectID": "02-mapping-data.html#joining-attribute-data",
    "href": "02-mapping-data.html#joining-attribute-data",
    "title": "1 R for Spatial Analysis",
    "section": "",
    "text": "We now have our language dataset (att) with the number of isiXhosa speakers in Cape Town, organised by sub-place, as well as a spatial dataset containing the boundaries of these sub-places (cpt). We can now join this table data to our spatial data using an Attribute Join.\n\n\n\n\n\n\nAn attribute join links two datasets based on a common attribute, enabling the ‘matching’ of rows between them.\n\n\n\n\n\nFigure 1: Attribute Joins.\n\n\n\n\nTo perform a successful join, each dataset must contain a unique identifying (UID) field. This could be a code, a name, or any other consistent identifier. It is crucial that the ID field is accurate across both datasets, with no typos or inconsistencies (e.g., “City of Cape Town” is not the same as “The City of Cape Town”). Whenever possible, it is preferable to use unique codes rather than names, as codes reduce the likelihood of errors and mismatches.\n\n\n\nBefore proceeding with the join, we need to verify that a matching UID exists in both datasets. Let’s look at the column names in our datasets again:\n\n\n\nR code\n\n# inspect\nnames(att)\n\n\n[1] \"sp_code\"  \"sp_pop\"   \"sp_xhosa\"\n\nnames(cpt)\n\n [1] \"sp_code\"    \"sp_name\"    \"mp_code\"    \"mp_name\"    \"mn_mdb_c\"  \n [6] \"mn_code\"    \"mn_name\"    \"dc_mdb_c\"   \"dc_mn_c\"    \"dc_name\"   \n[11] \"pr_mdb_c\"   \"pr_code\"    \"pr_name\"    \"albers_are\" \"shape_leng\"\n[16] \"shape_area\" \"geom\"      \n\n\nThe sp_code columns looks promising as it features in both datasets. We can quickly sort both columns and have a peek at the data:\n\n\n\nR code\n\n# inspect att\nhead(sort(att$sp_code))\n\n\n[1] 199001001 199002001 199002002 199002003 199003001 199004001\n\n# inspect cpt\nhead(sort(cpt$sp_code))\n\n[1] \"199001001\" \"199002001\" \"199002002\" \"199002003\" \"199003001\" \"199004001\"\n\n\nThey seem to contain similar values, so that is promising. Let us try to join the attribute data onto the spatial data:\n\n\n\nR code\n\n# join attribute data onto spatial data\ncpt &lt;- cpt |&gt;\n    left_join(att, by = c(sp_code = \"sp_code\"))\n\n\nYou will notice that the join results in an error.\nWhere the sub place codes in the att object are stored as numbers, the sub place codes in the cpt object are stored as strings. We can fix this by casting the number to characters:\n\n\n\nR code\n\n# change data type\natt &lt;- att |&gt;\n    mutate(sp_code = as.character(sp_code))\n\n# inspect\ntypeof(att$sp_code)\n\n\nWe can now try to join the datasets together again:\n\n\n\nR code\n\n# join attribute data onto spatial data\ncpt &lt;- cpt |&gt;\n    left_join(att, by = c(sp_code = \"sp_code\"))"
  }
]
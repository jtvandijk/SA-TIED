# R for Spatial Analysis

## Loading spatial data
Open a new script within your `Geospatial-Workshop24` project and save this as `02-language-maps.r`. We will start again by loading the libraries that we will need. You have been introduced to the `tidyverse` library last session, but now we are adding the `sf` library to read and load our spatial data as well as the `tmap` library to visualise our spatial data:

```{r}
#| label: 02-load-libraries
#| classes: styled-output
#| echo: True
#| eval: True
#| output: False
#| tidy: True
#| filename: "R code"
# load libraries
library(tidyverse)
library(sf)
library(tmap)
```

```{r}
#| label: 02-tmap-settings
#| classes: styled-output
#| echo: False
#| warning: False
#| message: False
#| eval: True
# ensure tmap is set to plot
tmap_mode("plot")
```

```{r}
#| label: 02-maxprint
#| echo: False
#| eval: True
options(max.print=100)
``` 

We will continue working with the `.csv` dataset that we prepared and saved in the previous session, so let us make sure it is loaded properly:

```{r}
#| label: 02-load-csv
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| cache: True
#| filename: "R code"
# load data
att <- read_csv('data/attributes/language.csv')
``` 

You can inspect the dataframe by using the `View()` function.

Next, we need a corresponding spatial dataset that contains the Cape Town's sub places and save it in your `data/spatial` folder.

| File                    | Type          | Link |
| :------                 | :------       | :------ |
| Cape Town Sub Places    | `GeoPackage`  | [Download](https://github.com/jtvandijk/SA-TIED/tree/master/data/spatial/subplace-cape-town-2013.gpkg) |

::: {.callout-note}
You may have used spatial data before and noticed that we did not download a collection of files known as a `shapefile` but a `GeoPackage` instead. Whilst `shapefiles` are still being used, `GeoPackage` is modern and portable file format. Have a look at this article on *towardsdatascience.com* for an excellent explanation on why one should use `GeoPackage` files over `shapefiles` where possible: [[Link]](https://towardsdatascience.com/why-you-need-to-use-geopackage-files-instead-of-shapefile-or-geojson-7cb24fe56416)
:::

Let us load the file and store it into an object called `cpt`. We can do this as follows:

```{r}
#| label: 02-load-gpkg
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| cache: True
#| filename: "R code"
# load data
cpt <- st_read("data/spatial/subplace-cape-town-2013.gpkg")
``` 

You should also see the `cpt` variable appear in your environment window.

## Exploring spatial data
As this is the first time we have loaded spatial data into R, let's go for a little exploration of how we can interact with our spatial dataframe. The first thing we want to do when we load spatial data is to make a quick map to check whether everything is in order. To do this, we can use the same function we used before: `plot()`:

```{r}
#| label: 02-plot-cpt
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| cache: True
#| filename: "R code"
# plot data
plot(cpt, max.plot = 1)
``` 

You should see your `cpt` plot appear in your **Plots** window.

::: {.callout-warning}
The `plot()` function should not to be used to make publishable maps but can be used as a quick way of inspecting your spatial data.
:::

Just as with a tabular dataframe, we can inspect the spatial data frame:

```{r}
#| label: 02-inspect-data-cpt
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect columns, rows
ncol(cpt)
nrow(cpt)

# inspect data
head(cpt)

# inspect column names
names(cpt)
```

We can also again establish the class of our data:

```{r}
#| label: 02-class-data-cpt
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect
class(cpt)
``` 

We should see our data is an `sf` dataframe, which is what we want and we can move on.

## Joining attribute data
We now have our language dataset (`att`) with the number of isiXhosa speakers in Cape Town, organised by sub-place, as well as a spatial dataset containing the boundaries of these sub-places (`cpt`). We can now join this table data to our spatial data using an **Attribute Join**.

::: {.callout-note}
An attribute join links two datasets based on a common attribute, enabling the ‘matching’ of rows between them.

```{r} 
#| label: fig-join-attributes
#| echo: False 
#| cache: True
#| fig-cap: "Attribute Joins."
knitr::include_graphics('images/w02/attribute-joins.png')
```

To perform a successful join, each dataset must contain a unique identifying (UID) field. This could be a code, a name, or any other consistent identifier. It is crucial that the ID field is accurate across both datasets, with no typos or inconsistencies (e.g., "City of Cape Town" is not the same as "The City of Cape Town"). Whenever possible, it is preferable to use unique codes rather than names, as codes reduce the likelihood of errors and mismatches.
:::

Before proceeding with the join, we need to verify that a matching UID exists in both datasets. Let's look at the column names in our datasets again:

```{r}
#| label: 02-names-att-cpt
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect
names(att)
names(cpt)
``` 

The `sp_code` columns looks promising as it features in both datasets. We can quickly sort both columns and have a peek at the data:

```{r}
#| label: 02-sort-att-cpt
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect att
head(sort(att$sp_code))

#inspect cpt
head(sort(cpt$sp_code))
``` 

They seem to contain similar values, so that is promising. Let us try to join the attribute data onto the spatial data:

```{r}
#| label: 02-join-att-cpt-fail
#| classes: styled-output
#| echo: True
#| eval: False
#| tidy: False
#| filename: "R code"
# join attribute data onto spatial data
cpt <- cpt |> 
  left_join(att, by = c("sp_code" = "sp_code"))
``` 
You will notice that the join results in an error. 

Where the sub place codes in the `att` object are stored as numbers, the sub place codes in the `cpt` object are stored as strings. We can fix this by casting the number to characters:

```{r}
#| label: 02-cast-att
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# change data type
att <- att |>
  mutate(sp_code = as.character(sp_code))

# inspect
typeof(att$sp_code)
``` 

We can now try to join the datasets together again:

```{r}
#| label: 02-join-att-cpt
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: False
#| filename: "R code"
# join attribute data onto spatial data
cpt <- cpt |> 
  left_join(att, by = c("sp_code" = "sp_code"))
``` 

We can explore the joined data in usual fashion:

```{r}
#| label: 02-inspect-join
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect columns, rows
ncol(cpt)
nrow(cpt)

# inspect data
head(cpt)

# inspect column names
names(cpt)
```

Always inspect your join to ensure everything looks as expected. A good way to do this is by using the `View()` function to check for any unexpected missing values, which are marked as `NA`. We can further compare the total number of rows in the spatial dataset with the total number of non-`NA` values in the joined columns:

```{r}
#| label: 02-inspect-na
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect
nrow(cpt)

# inspect attribute data: sp_pop
sum(!is.na(cpt$sp_pop))

# inspect attribute data: sp_xhosas 
sum(!is.na(cpt$sp_xhosa))
```

Out of the 921 sub-places, only 878 have data on the number of isiXhosa speakers and the total population. However, this discrepancy may not be due to the join; it could simply be that the original dataset lacks data for some units. Let's confirm this:

```{r}
#| label: 02-confirm-na
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# inspect
nrow(att)
```

This confirms that all our full attribute dataset has been linked to the spatial dataset. 

::: {.callout-warning}
It is important to confirm the source of any `NA` values that are introduced to the dataset to ensure these are genuine. In our case the [South African Census Community Profiles 2011](https://www.statssa.gov.za/?page_id=3839) dataset includes sub places with no population, which typically correspond to industrial areas.
:::

Since we know these `NA` values are not truly missing but represent structural zeroes, we can replace them with `0`. However, this step is not strictly necessary.

```{r}
#| label: 02-replace-na
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# replace NAs
cpt <- cpt |>
  mutate(sp_pop = if_else(is.na(sp_pop), 0, sp_pop),
         sp_xhosa = if_else(is.na(sp_xhosa), 0, sp_xhosa))
```

We are almost ready to map the data. We only need to add the proportion of isiXhosa speakers within each sub place to the data frame:

```{r}
#| label: 02-xhosa-prop
#| classes: styled-output
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# calculate percentages
cpt <- cpt |>
  mutate(sp_prop_xhosa = sp_xhosa / sp_pop)
```

## Mapping spatial data
For our map-making, we will use one of the two primary visualisation libraries for spatial data: `tmap.` `tmap` offers a flexible, layer-based approach that makes it easy to create various types of thematic maps, such as choropleths and bubble maps. One of the standout features of `tmap` is its quick plotting function, `qtm()`, which allows you to generate basic maps with minimal effort.

```{r}
#| label: fig-02-qtm
#| fig-cap: Quick thematic map. 
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# quick thematic map
qtm(cpt, fill="sp_prop_xhosa")
``` 

In this case, the `fill()` argument in `tmap` is how we instruct the library to create a choropleth map based on the values in the specified column. If we set `fill()` to NULL, only the borders of our polygons will be drawn, without any color fill. The `qtm()` function in tmap is versatile, allowing us to pass various parameters to customise the aesthetics of our map. By checking the function's documentation, you can explore the full list of available parameters. For instance, to set the borders of our Cape Town polygons to white, we can use the `borders` parameter:


```{r}
#| label: fig-02-qtm-borders
#| fig-cap: Quick thematic map with white borders.
#| echo: True
#| eval: True
#| tidy: True
#| filename: "R code"
# quick thematic map 
qtm(cpt, fill="sp_prop_xhosa", borders = "white")
``` 

The map does not look quite right yet. While we can continue tweaking parameters in the `qtm()` function to improve it, `qtm()` is somewhat limited in its functionality and is primarily intended for quickly inspecting your data and creating basic maps. For more complex and refined map-making with the `tmap` library, it is better to use the main plotting method that starts with the `tm_shape()` function. 

::: {.callout-note}
The primary approach to creating maps in `tmap` involves using a l [layered grammar of graphics](https://towardsdatascience.com/a-comprehensive-guide-to-the-grammar-of-graphics-for-effective-visualization-of-multi-dimensional-1f92b4ed4149) to build up your map, starting with the `tm_shape()` function. This function, when provided with a spatial dataframe, captures the spatial information of your data, including its projection and geometry, and creates a spatial object. While you can override certain aspects of the spatial data (such as its projection) using the function's parameters, the essential role of tm_shape() is to instruct R to "use this object as the basis for drawing the shapes." 

To actually render the shapes, you need to add a layer that specifies the type of shape you want R to draw from this spatial information—such as polygons for our data. This layer function tells R to "draw my spatial object as `X`," where `X` represents the type of shape. Within this layer, you can also provide additional details to control how R draws your shapes. Further, you can add more layers to include other spatial objects and their corresponding shapes on your map. Finally, layout options can be specified through a layout layer, allowing you to customize the overall appearance and arrangement of your map.
:::









